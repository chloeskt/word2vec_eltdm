{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083d0bf-d23a-45b1-b40c-ab0e765b7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append('/home/kaliayev/Documents/ENSAE/elements_logiciels/word2vec_eltdm')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8d855-3872-4774-bb10-ac73d5a02a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2vec_eltdm.common import Tokenizer, VocabCreator, DataLoader, TokenCleaner, Preprocessor, Subsampler, evaluate\n",
    "from word2vec_eltdm.word2vec_accelerated import PytorchNegWord2Vec, NegativeSamplingLoss, train_NSL, update_best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f517c-5602-449e-af4d-c881cff6c7c9",
   "metadata": {},
   "source": [
    "## Get data and create vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16e016-0677-4910-b630-53729efafd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/text8.txt\"\n",
    "\n",
    "RATIO = 0.2\n",
    "return_only_train = True\n",
    "tokenizer = Tokenizer(datapath)\n",
    "token_cleaner = TokenCleaner(freq_threshold=5)\n",
    "vocab_creator = VocabCreator()\n",
    "text8_dataset = Preprocessor(tokenizer, token_cleaner, vocab_creator, RATIO, return_only_train).preprocess()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5aaebb-65ad-4424-a030-42b5323710d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of our vocabulary:\", len(text8_dataset.tokens_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d804d6-3844-40d9-ad5b-21a6e5aef46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tokens in our train dataset:\", len(text8_dataset.train_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6be05b-fc5a-4b24-acca-85b56190cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tokens in our val dataset:\", len(text8_dataset.val_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ebad4-5d79-486a-80b5-7e46c00f9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tokens in our test dataset:\", len(text8_dataset.test_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b10ad-ecaa-432b-9cb7-78b685b22475",
   "metadata": {},
   "source": [
    "## Subsampling of frequent words, as in Mikolov 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f34449-b003-4adf-a869-11054cfe2cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subsampler = Subsampler(text8_dataset.train_tokens)\n",
    "text8_dataset.train_tokens, text8_dataset.frequencies = subsampler.subsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0e1cf-47fb-4d76-a33b-af57574af026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of our vocabulary after subsampling of frequent words, for train:\", len(text8_dataset.tokens_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44184e2-52b4-4063-8d19-d6efbb7139a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tokens in train dataset:\", len(text8_dataset.train_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007df8b-5765-4aff-9098-cf931f2a00d9",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72de46-a391-4740-8a84-daa0a79e4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "batch_size = 512\n",
    "train_dataloader = DataLoader(text8_dataset, text8_dataset.train_tokens, window, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01627b9b-7c44-41fb-a823-826ac32fc632",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbafcb7-5117-425e-8308-4cf8d06f505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the parameters\n",
    "len_vocab = len(text8_dataset.tokens_to_id)\n",
    "embedding_size = 300\n",
    "learning_rate = 0.003\n",
    "n_samples = 5\n",
    "epochs = 10\n",
    "\n",
    "# Get our noise distribution\n",
    "word_freqs = np.array(sorted(text8_dataset.frequencies.values(), reverse=True))\n",
    "unigram_dist = word_freqs / word_freqs.sum()\n",
    "noise_dist = unigram_dist ** (0.75) / np.sum(unigram_dist ** (0.75))\n",
    "\n",
    "# instantiate the model\n",
    "model = PytorchNegWord2Vec(\n",
    "    len_vocab,\n",
    "    embedding_size,\n",
    "    noise_dist=noise_dist,\n",
    ").to(device)\n",
    "model.initialize_weights()\n",
    "\n",
    "criterion = NegativeSamplingLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4561f68-f821-4b25-abe5-a03a12b7eeba",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422f48a-b406-4aba-8d17-504836ae2ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train for some number of epochs\n",
    "train_loss_history = []\n",
    "tbar = trange(epochs)\n",
    "\n",
    "for epoch in tbar:\n",
    "    print(f\"###################### EPOCH {epoch} ###########################\")\n",
    "\n",
    "    train_loss = train_NSL(model, train_dataloader, criterion, optimizer, n_samples)\n",
    "    print(\"Training loss:\", train_loss.item())\n",
    "    train_loss_history.append(train_loss.item())\n",
    "\n",
    "    # Keep track of the best model\n",
    "    update_best_loss(model, train_loss)\n",
    "\n",
    "    embeddings = model.embedding_input.weight.data.detach().cpu().numpy()\n",
    "    evaluate(embeddings, text8_dataset.id_to_tokens, nb_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3202a7c-73d3-4c00-a2b0-4dcef4dd4b7b",
   "metadata": {},
   "source": [
    "## Evaluation on the task of word similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e336c-c492-4a8c-b27e-0c531fbafcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../word2vec_eltdm/models/NegWord2Vec_2.7252233850736785.p\"\n",
    "with open(filepath, \"rb\") as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824177c1-0290-4e5a-99e7-9c04b0a9f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model[\"NegWord2Vec\"]\n",
    "embeddings = model.embedding_input.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da161421-06d5-4594-93c2-bbba8fa4bac2",
   "metadata": {},
   "source": [
    "### Evaluate using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e693c8-2109-4540-a27d-a7645776e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(embeddings, text8_dataset.id_to_tokens, nb_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab0a93-472d-43fb-b46c-d3d6a2dd1f11",
   "metadata": {},
   "source": [
    "### t-SNE embedding visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167a904-ba0a-4a4c-afe4-010eafbe667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_tsne(embeddings, text8_dataset.id_to_tokens, nb_words = 400)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}