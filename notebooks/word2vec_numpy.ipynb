{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b083d0bf-d23a-45b1-b40c-ab0e765b7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append('/home/kaliayev/Documents/ENSAE/elements_logiciels/word2vec_eltdm')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a8d855-3872-4774-bb10-ac73d5a02a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from word2vec_eltdm.word2vec_numpy import (\n",
    "    Tokenizer, VocabCreator, DataLoader, TokenCleaner, Preprocessor,\n",
    "    Subsampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f517c-5602-449e-af4d-c881cff6c7c9",
   "metadata": {},
   "source": [
    "## Get data and create vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db16e016-0677-4910-b630-53729efafd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/text8.txt\"\n",
    "\n",
    "tokenizer = Tokenizer(datapath)\n",
    "token_cleaner = TokenCleaner(freq_threshold=3)\n",
    "vocab_creator = VocabCreator()\n",
    "tokens, words_to_id, id_to_words = Preprocessor(tokenizer, token_cleaner, vocab_creator).preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5aaebb-65ad-4424-a030-42b5323710d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our vocabulary: 82146\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of our vocabulary:\", len(words_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d804d6-3844-40d9-ad5b-21a6e5aef46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in our dataset: 10648302\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in our dataset:\", len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b10ad-ecaa-432b-9cb7-78b685b22475",
   "metadata": {},
   "source": [
    "## Subsampling of frequent words, as in Mikolov 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f34449-b003-4adf-a869-11054cfe2cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subsampler = Subsampler(words_to_id, id_to_words, tokens)\n",
    "tokens, words_to_id, id_to_words = subsampler.subsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f0e1cf-47fb-4d76-a33b-af57574af026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our vocabulary after subsampling of frequent words: 82146\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of our vocabulary after subsampling of frequent words:\", len(words_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44184e2-52b4-4063-8d19-d6efbb7139a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in  dataset: 3859445\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens in  dataset:\", len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007df8b-5765-4aff-9098-cf931f2a00d9",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b72de46-a391-4740-8a84-daa0a79e4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(tokens, words_to_id, window, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42cfbb11-47dd-46be-8da8-568dc9c118a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72144de0efcf4adcb111f51530bdfb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15075 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH 100 done\n",
      "BATCH 200 done\n",
      "BATCH 300 done\n",
      "BATCH 400 done\n",
      "BATCH 500 done\n",
      "BATCH 600 done\n",
      "BATCH 700 done\n",
      "BATCH 800 done\n",
      "BATCH 900 done\n",
      "BATCH 1000 done\n",
      "BATCH 1100 done\n",
      "BATCH 1200 done\n",
      "BATCH 1300 done\n",
      "BATCH 1400 done\n",
      "BATCH 1500 done\n",
      "BATCH 1600 done\n",
      "BATCH 1700 done\n",
      "BATCH 1800 done\n",
      "BATCH 1900 done\n",
      "BATCH 2000 done\n",
      "BATCH 2100 done\n",
      "BATCH 2200 done\n",
      "BATCH 2300 done\n",
      "BATCH 2400 done\n",
      "BATCH 2500 done\n",
      "BATCH 2600 done\n",
      "BATCH 2700 done\n",
      "BATCH 2800 done\n",
      "BATCH 2900 done\n",
      "BATCH 3000 done\n",
      "BATCH 3100 done\n",
      "BATCH 3200 done\n",
      "BATCH 3300 done\n",
      "BATCH 3400 done\n",
      "BATCH 3500 done\n",
      "BATCH 3600 done\n",
      "BATCH 3700 done\n",
      "BATCH 3800 done\n",
      "BATCH 3900 done\n",
      "BATCH 4000 done\n",
      "BATCH 4100 done\n",
      "BATCH 4200 done\n",
      "BATCH 4300 done\n",
      "BATCH 4400 done\n",
      "BATCH 4500 done\n",
      "BATCH 4600 done\n",
      "BATCH 4700 done\n",
      "BATCH 4800 done\n",
      "BATCH 4900 done\n",
      "BATCH 5000 done\n",
      "BATCH 5100 done\n",
      "BATCH 5200 done\n",
      "BATCH 5300 done\n",
      "BATCH 5400 done\n",
      "BATCH 5500 done\n",
      "BATCH 5600 done\n",
      "BATCH 5700 done\n",
      "BATCH 5800 done\n",
      "BATCH 5900 done\n",
      "BATCH 6000 done\n",
      "BATCH 6100 done\n",
      "BATCH 6200 done\n",
      "BATCH 6300 done\n",
      "BATCH 6400 done\n",
      "BATCH 6500 done\n",
      "BATCH 6600 done\n",
      "BATCH 6700 done\n",
      "BATCH 6800 done\n",
      "BATCH 6900 done\n",
      "BATCH 7000 done\n",
      "BATCH 7100 done\n",
      "BATCH 7200 done\n",
      "BATCH 7300 done\n",
      "BATCH 7400 done\n",
      "BATCH 7500 done\n",
      "BATCH 7600 done\n",
      "BATCH 7700 done\n",
      "BATCH 7800 done\n",
      "BATCH 7900 done\n",
      "BATCH 8000 done\n",
      "BATCH 8100 done\n",
      "BATCH 8200 done\n",
      "BATCH 8300 done\n",
      "BATCH 8400 done\n",
      "BATCH 8500 done\n",
      "BATCH 8600 done\n",
      "BATCH 8700 done\n",
      "BATCH 8800 done\n",
      "BATCH 8900 done\n",
      "BATCH 9000 done\n",
      "BATCH 9100 done\n",
      "BATCH 9200 done\n",
      "BATCH 9300 done\n",
      "BATCH 9400 done\n",
      "BATCH 9500 done\n",
      "BATCH 9600 done\n",
      "BATCH 9700 done\n",
      "BATCH 9800 done\n",
      "BATCH 9900 done\n",
      "BATCH 10000 done\n",
      "BATCH 10100 done\n",
      "BATCH 10200 done\n",
      "BATCH 10300 done\n",
      "BATCH 10400 done\n",
      "BATCH 10500 done\n",
      "BATCH 10600 done\n",
      "BATCH 10700 done\n",
      "BATCH 10800 done\n",
      "BATCH 10900 done\n",
      "BATCH 11000 done\n",
      "BATCH 11100 done\n",
      "BATCH 11200 done\n",
      "BATCH 11300 done\n",
      "BATCH 11400 done\n",
      "BATCH 11500 done\n",
      "BATCH 11600 done\n",
      "BATCH 11700 done\n",
      "BATCH 11800 done\n",
      "BATCH 11900 done\n",
      "BATCH 12000 done\n",
      "BATCH 12100 done\n",
      "BATCH 12200 done\n",
      "BATCH 12300 done\n",
      "BATCH 12400 done\n",
      "BATCH 12500 done\n",
      "BATCH 12600 done\n",
      "BATCH 12700 done\n",
      "BATCH 12800 done\n",
      "BATCH 12900 done\n",
      "BATCH 13000 done\n",
      "BATCH 13100 done\n",
      "BATCH 13200 done\n",
      "BATCH 13300 done\n",
      "BATCH 13400 done\n",
      "BATCH 13500 done\n",
      "BATCH 13600 done\n",
      "BATCH 13700 done\n",
      "BATCH 13800 done\n",
      "BATCH 13900 done\n",
      "BATCH 14000 done\n",
      "BATCH 14100 done\n",
      "BATCH 14200 done\n",
      "BATCH 14300 done\n",
      "BATCH 14400 done\n",
      "BATCH 14500 done\n",
      "BATCH 14600 done\n",
      "BATCH 14700 done\n",
      "BATCH 14800 done\n",
      "BATCH 14900 done\n",
      "BATCH 15000 done\n",
      "Lopped through all the dataset in 5773.5713 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for batch in tqdm(dataloader):\n",
    "    X, y = batch[\"X\"], batch[\"y\"]\n",
    "end = time.perf_counter()\n",
    "print(f\"Lopped through all the dataset in {end - start:0.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
